stages:
  - build
  - docker-push
  - deploy

variables:
  DOCKER_IMAGE_NAME: ${DOCKER_IMAGE_NAME}
  DOCKER_USERNAME: ${DOCKER_USERNAME}
  DOCKER_PASSWORD: ${DOCKER_PASSWORD}

# Build stage - runs on development and main branches
build:
  stage: build
  image: eclipse-temurin:21-jdk
  script:
    - cd accommodation-be
    - chmod +x ./gradlew
    - ./gradlew clean build -x test
    - cp $(find build/libs -name "*.jar" | head -n 1) app.jar
  artifacts:
    paths:
      - accommodation-be/app.jar
      - accommodation-be/Dockerfile
      - accommodation-be/k8s/deployment.yaml
      - accommodation-be/k8s/service.yaml
      - accommodation-be/k8s/ingress.yaml
    expire_in: 1 hour
  only:
    - development
    - main

# Docker push - builds and pushes image with appropriate tag
docker-push:
  stage: docker-push
  image:
    name: gcr.io/kaniko-project/executor:v1.23.2-debug
    entrypoint: [""]
  dependencies:
    - build
  script:
    - mkdir -p /kaniko/.docker
    - echo "{\"auths\":{\"https://index.docker.io/v1/\":{\"auth\":\"$(printf "%s:%s" "${DOCKER_USERNAME}" "${DOCKER_PASSWORD}" | base64 | tr -d '\n')\"}}}" > /kaniko/.docker/config.json
    # Set image tag based on branch
    - |
      if [ "$CI_COMMIT_BRANCH" == "main" ]; then
        export IMAGE_TAG="latest"
      elif [ "$CI_COMMIT_BRANCH" == "development" ]; then
        export IMAGE_TAG="staging"
      else
        export IMAGE_TAG="$CI_COMMIT_SHORT_SHA"
      fi
    - /kaniko/executor
      --context "${CI_PROJECT_DIR}/accommodation-be"
      --dockerfile "${CI_PROJECT_DIR}/accommodation-be/Dockerfile"
      --destination "${DOCKER_IMAGE_NAME}:${IMAGE_TAG}"
      --destination "${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
  only:
    - development
    - main

# Deploy to Staging - auto deploy from development branch
deploy:staging:
  stage: deploy
  image: alpine:latest
  dependencies:
    - build
  variables:
    IMAGE_TAG: staging
    DEPLOYMENT_NAME: accommodation-staging
    CONFIG_NAME: accommodation-staging-config
    SECRET_NAME: accommodation-staging-secret
  before_script:
    - apk add --no-cache openssh bash
    - mkdir -p ~/.ssh
    - printf "%s\n" "$EC2_SSH_KEY" > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - ssh-keyscan -H $EC2_HOST >> ~/.ssh/known_hosts
  script:
    # Generating Kubernetes ConfigMap manifest for staging
    - |
      printf "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: ${CONFIG_NAME}\ndata:\n  DATABASE_URL_PROD: \"%s\"\n  DATABASE_USERNAME: \"%s\"\n" \
        "$DATABASE_URL_STAGING" "$DATABASE_USERNAME" > config.yaml

    # Generating Kubernetes Secret manifest for staging
    - |
      printf "apiVersion: v1\nkind: Secret\nmetadata:\n  name: ${SECRET_NAME}\ntype: Opaque\nstringData:\n  DATABASE_PASSWORD: \"%s\"\n  JWT_SECRET_KEY: \"%s\"\n  CORS_ALLOWED_ORIGINS: \"%s\"\n" \
        "$DATABASE_PASSWORD" "$JWT_SECRET_KEY" "$CORS_ALLOWED_ORIGINS_STAGING" > secret.yaml

    # Update deployment.yaml with staging image tag and names
    - sed "s|\${DOCKER_IMAGE_NAME}:\${IMAGE_TAG}|$DOCKER_IMAGE_NAME:staging|" accommodation-be/k8s/deployment.yaml > deployment.yaml
    - sed -i "s|accommodation-ti|${DEPLOYMENT_NAME}|g" deployment.yaml
    - sed -i "s|accommodation-ti-config|${CONFIG_NAME}|g" deployment.yaml
    - sed -i "s|accommodation-ti-secret|${SECRET_NAME}|g" deployment.yaml

    # Update service.yaml with staging names
    - sed "s|accommodation-ti|${DEPLOYMENT_NAME}|g" accommodation-be/k8s/service.yaml > service.yaml

    # Update ingress.yaml with staging domain and names
    - sed "s|accommodation-ti-ingress|${DEPLOYMENT_NAME}-ingress|" accommodation-be/k8s/ingress.yaml > ingress.yaml
    - sed -i "s|accommodation-ti-service|${DEPLOYMENT_NAME}-service|g" ingress.yaml
    - sed -i "s|2306214510-be.hafizmuh.site|staging-2306214510-be.hafizmuh.site|" ingress.yaml

    # Transfer configuration files to EC2
    - scp config.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-config.yaml
    - scp secret.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-secret.yaml
    - scp deployment.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-deployment.yaml
    - scp service.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-service.yaml
    - scp ingress.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-ingress.yaml

    # Apply Kubernetes manifests on EC2
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-config.yaml"
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-secret.yaml"
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-deployment.yaml"
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-service.yaml"
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-ingress.yaml"
  environment:
    name: staging
    url: https://staging-2306214510-be.hafizmuh.site
  only:
    - development

# Deploy to Production - manual deploy from main branch
deploy:production:
  stage: deploy
  image: alpine:latest
  dependencies:
    - build
  variables:
    IMAGE_TAG: latest
    DEPLOYMENT_NAME: accommodation-ti
    CONFIG_NAME: accommodation-ti-config
    SECRET_NAME: accommodation-ti-secret
  before_script:
    - apk add --no-cache openssh bash
    - mkdir -p ~/.ssh
    - printf "%s\n" "$EC2_SSH_KEY" > ~/.ssh/id_rsa
    - chmod 600 ~/.ssh/id_rsa
    - ssh-keyscan -H $EC2_HOST >> ~/.ssh/known_hosts
  script:
    # Generating Kubernetes ConfigMap manifest for production
    - |
      printf "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: ${CONFIG_NAME}\ndata:\n  DATABASE_URL_PROD: \"%s\"\n  DATABASE_USERNAME: \"%s\"\n" \
        "$DATABASE_URL_PROD" "$DATABASE_USERNAME" > config.yaml

    # Generating Kubernetes Secret manifest for production
    - |
      printf "apiVersion: v1\nkind: Secret\nmetadata:\n  name: ${SECRET_NAME}\ntype: Opaque\nstringData:\n  DATABASE_PASSWORD: \"%s\"\n  JWT_SECRET_KEY: \"%s\"\n  CORS_ALLOWED_ORIGINS: \"%s\"\n" \
        "$DATABASE_PASSWORD" "$JWT_SECRET_KEY" "$CORS_ALLOWED_ORIGINS_PROD" > secret.yaml

    # Update deployment.yaml with production image tag
    - sed "s|\${DOCKER_IMAGE_NAME}:\${IMAGE_TAG}|$DOCKER_IMAGE_NAME:latest|" accommodation-be/k8s/deployment.yaml > deployment.yaml

    # Transfer configuration files to EC2
    - scp config.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-config.yaml
    - scp secret.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-secret.yaml
    - scp deployment.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-deployment.yaml
    - scp accommodation-be/k8s/service.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-service.yaml
    - scp accommodation-be/k8s/ingress.yaml $EC2_USER@$EC2_HOST:~/app/k8s/${DEPLOYMENT_NAME}-ingress.yaml

    # Apply Kubernetes manifests on EC2
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-config.yaml"
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-secret.yaml"
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-deployment.yaml"
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-service.yaml"
    - ssh $EC2_USER@$EC2_HOST "sudo k3s kubectl apply -f ~/app/k8s/${DEPLOYMENT_NAME}-ingress.yaml"
  environment:
    name: production
    url: https://2306214510-be.hafizmuh.site
  when: manual  # Requires manual trigger in GitLab UI
  only:
    - main
